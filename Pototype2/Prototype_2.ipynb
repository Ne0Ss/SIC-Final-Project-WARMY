{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf9b912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.744704961776733\n",
      "4.78666877746582\n",
      "4.981351852416992\n",
      "5.02834939956665\n",
      "5.06038498878479\n",
      "5.237020015716553\n",
      "5.2710254192352295\n",
      "5.4167640209198\n",
      "5.539930105209351\n",
      "5.640017509460449\n",
      "5.691987991333008\n",
      "5.74802827835083\n",
      "5.79602575302124\n",
      "5.826123476028442\n",
      "5.862478733062744\n",
      "5.91503381729126\n",
      "5.933045387268066\n",
      "5.999322175979614\n",
      "6.047061443328857\n",
      "6.187986850738525\n",
      "6.228979825973511\n",
      "6.261936664581299\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "from scipy.spatial import distance as dist\n",
    "mixer.init()\n",
    "#face mesh params and drawing otions\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n",
    "drawSpec = mpDraw.DrawingSpec(thickness=1,circle_radius=0)\n",
    "camera = 0\n",
    "\n",
    "#opencv objects detection\n",
    "classNames = ['person', '0', '0', '0', '0', '0', '0', '0','0', '0', '0', '0', '0', '0',\n",
    "              '0', '0', '0', '0', '0', '0', '0', '0', '0', '0','0', '0', '0', '0', '0',\n",
    "              'eye glasses', '0', '0','0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
    "              '0', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "              'banana', 'apple', 'sandwich','orange', 'broccoli', 'carrot', 'hot dog', \n",
    "              'pizza', 'donut', 'cake', '0', '0','0', '0', '0', '0', '0', '0', '0','0',\n",
    "              '0', '0', '0', '0', '0', 'cell phone', '0', '0','0', '0', '0', '0', 'book',\n",
    "              '0', '0', '0','0', '0', '0', '0']\n",
    "\n",
    "# options = \"options.txt\"\n",
    "# with open(options,'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "### PARAMETRES ###\n",
    "draw = True\n",
    "First_cfg = False\n",
    "#~~~~~~~~~~~~~~~~~~~~~#\n",
    "if First_cfg :\n",
    "    face_length = 400\n",
    "    pTime = 0\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "\n",
    "    while cv2.waitKey(1) != ord('d') :\n",
    "        success, img= cap.read()\n",
    "        if not success:\n",
    "            print(\"No camera detected\")\n",
    "            break\n",
    "        #converting the image from BGR to RGB\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceMesh.process(imgRGB)\n",
    "        faces = []\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for faceLms in results.multi_face_landmarks:\n",
    "                if draw:\n",
    "                    mpDraw.draw_landmarks(img,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "                face = []\n",
    "                for id, lm in enumerate(faceLms.landmark):\n",
    "                    ih, iw, ic = img.shape\n",
    "                    x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                    #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                    face.append([x,y])\n",
    "                #calculation distances and facing direction\n",
    "                face_length = dist.euclidean(face[10],face[152])\n",
    "                left_dist_cfg = dist.euclidean(face[1],face[361])\n",
    "                right_dist_cfg = dist.euclidean(face[1],face[132])\n",
    "                direction_cfg= (right_dist_cfg-left_dist_cfg)/face_length\n",
    "                #afficher la direction [-1,1]\n",
    "                cv2.putText(img, str(round(direction_cfg,2)), (400,400),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "\n",
    "                faces.append(face)\n",
    "        #calculer les fps \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime \n",
    "        cv2.putText(img, \"Prenez votre position de conduite par defaut\", (20,70),cv2.FONT_HERSHEY_PLAIN,1.5, (255,100,200), 3)\n",
    "        cv2.putText(img,f'FPS: {int(fps)}',(70,400),cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "        cv2.imshow(\"Video\", img)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "### PARAMETRES ###\n",
    "\n",
    "OBJ_DETECTION = False\n",
    "DISTRACTION = False\n",
    "DROWSINESS = True\n",
    "\n",
    "draw = True\n",
    "audio_alarm = True\n",
    "EYE_AR_THRESH = 0.2\n",
    "TIME_closed_eyes = 2 #secondes\n",
    "TIME_open_mouth = 2 #secondes\n",
    "\n",
    "# Help = False\n",
    "\n",
    "#Audio Files\n",
    "TiredAudioFile = \"AUDIO/GetSomeRest.wav\"\n",
    "DistratedAudioFile = \"AUDIO/StayFocused.wav\"\n",
    "ClosedEyesAudioFile = \"AUDIO/WakeUp.wav\"\n",
    "SmokingAudioFile = \"AUDIO/StopSmoking.wav\"\n",
    "FoodAudioFile = \"AUDIO/StopEating.wav\"\n",
    "PhoneUsageAudioFile = \"AUDIO/PutDownPhone.wav\"\n",
    "\n",
    "#classeIdsof objects to detecte\n",
    "classes= ['1', 30, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 84]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "face_length = 400\n",
    "down_threshold = 30\n",
    "EYE_AR_CONSEC_FRAMES = 40\n",
    "YAWN_THRESH = 30\n",
    "YAWN_CONSEC_FRAMES = 40\n",
    "ALARM_Thresh = 30\n",
    "Time_Alarm_Loop = 5   #Secondes \n",
    "cpt_yawn_per_minute = 0 \n",
    "Alarm_time_yawn = 60 #Secondes \n",
    "Nb_Yawn = 2 # Number of Yawnings per 'Alarm_time_yawn'\n",
    "alarm_status = False\n",
    "alarm_status2 = False\n",
    "cpt = cpt2 = cpt3 = cpt4 = cpt5 = 0\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(300,300)\n",
    "net.setInputScale(1.0/127.5)\n",
    "net.setInputMean((127.5,127.5,127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "cap = cv2.VideoCapture(camera)\n",
    "pTime = 0\n",
    "while cv2.waitKey(1) != 27 :\n",
    "    success, img= cap.read()\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = faceMesh.process(imgRGB)\n",
    "    faces = []\n",
    "    \n",
    "    ########## OpenCV Object Detection ##########\n",
    "    if OBJ_DETECTION:\n",
    "        classIds, confs, bbox = net.detect(img,confThreshold=0.6)\n",
    "        if len(classIds) != 0:\n",
    "            for classId,confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "                if classId in classes:\n",
    "                    \n",
    "                    cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "                    cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),cv2.FONT_HERSHEY_COMPLEX,.8,(0,255,0),2)\n",
    "                    \n",
    "                    cpt3 += 1\n",
    "                    if cpt3 == 1:\n",
    "                        mixer.Sound(FoodAudioFile).play()\n",
    "                    if cpt3 >= ALARM_Thresh:\n",
    "                        cpt3 = 0\n",
    "                    \n",
    "                \n",
    "                if classId==77:\n",
    "                    cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "                    cv2.putText(img,'CELLPHONE DETECTED',(200,400),cv2.FONT_HERSHEY_COMPLEX,.8,(0,0,255),2)\n",
    "                    cpt4 += 1\n",
    "                    if cpt4 == 1: \n",
    "                        mixer.Sound(PhoneUsageAudioFile).play()\n",
    "                    if cpt4 >= ALARM_Thresh:\n",
    "                        cpt4 = 0\n",
    "                    \n",
    "                    \n",
    "    ########## Mediapipe FaceMesh Detection ##########\n",
    "    if results.multi_face_landmarks:\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            if draw:\n",
    "                mpDraw.draw_landmarks(img,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "            face = []\n",
    "            for id, lm in enumerate(faceLms.landmark):\n",
    "                ih, iw, ic = img.shape\n",
    "                x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                face.append([x,y])\n",
    "                \n",
    "            down_threshold = down_threshold / face_length\n",
    "            face_length = dist.euclidean(face[10],face[152])\n",
    "            down_threshold = down_threshold * face_length\n",
    "            left_dist = dist.euclidean(face[1],face[361])\n",
    "            right_dist= dist.euclidean(face[1],face[132])\n",
    "            down_dist= dist.euclidean(face[1],face[0])\n",
    "            direction= (right_dist-left_dist)/face_length\n",
    "            \n",
    "            upper_lip=[((face[13][0]+face[312][0]+face[267][0]+face[0][0]+face[37][0]+face[82][0])/6),\n",
    "                        ((face[13][1]+face[312][1]+face[267][1]+face[0][1]+face[37][1]+face[82][1])/6)]\n",
    "\n",
    "            lower_lip=[((face[14][0]+face[317][0]+face[314][0]+face[17][0]+face[84][0]+face[87][0])/6),\n",
    "                        ((face[14][1]+face[317][1]+face[314][1]+face[17][1]+face[84][1]+face[87][1])/6)]\n",
    "\n",
    "            A_eye_R = dist.euclidean(face[160],face[144])\n",
    "            B_eye_R = dist.euclidean(face[158],face[153])\n",
    "            C_eye_R = dist.euclidean(face[33],face[133])\n",
    "            R_ear = (A_eye_R + B_eye_R) / (2.0 * C_eye_R)\n",
    "\n",
    "            A_eye_L = dist.euclidean(face[385],face[380])\n",
    "            B_eye_L = dist.euclidean(face[387],face[373])\n",
    "            C_eye_L = dist.euclidean(face[362],face[263])\n",
    "            L_ear = (A_eye_L + B_eye_L) / (2.0 * C_eye_L)\n",
    "\n",
    "            ear = (R_ear + L_ear) / 2.0\n",
    "            dist1 = dist.euclidean(upper_lip,lower_lip)\n",
    "            \n",
    "            ########## Alarm conditions ##########\n",
    "            if DISTRACTION:\n",
    "                if direction>=-0.5+direction_cfg and direction<=0.5+direction_cfg and down_dist>down_threshold:\n",
    "                    cv2.putText(img, 'Good', (150,400),cv2.FONT_HERSHEY_PLAIN,2, (0,255,0), 3)\n",
    "                \n",
    "                if direction>0.5+direction_cfg:\n",
    "                    cv2.putText(img, 'Distacted', (350,250),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                    cpt5 +=1\n",
    "                    if cpt5 == 1:\n",
    "                        mixer.Sound(DistratedAudioFile).play()\n",
    "                    if cpt5 >= ALARM_Thresh:\n",
    "                        cpt5 = 0\n",
    "                    \n",
    "                \n",
    "                if direction<-0.5+direction_cfg:\n",
    "                    cv2.putText(img, 'Distacted', (150,250),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                    #mixer.Sound(DistratedAudioFile).play()\n",
    "                    cpt5 +=1\n",
    "                    if cpt5 == 1:\n",
    "                        mixer.Sound(DistratedAudioFile).play()\n",
    "                    if cpt5 >= ALARM_Thresh:\n",
    "                        cpt5 = 0\n",
    "                \n",
    "                if down_dist<=down_threshold:\n",
    "                    cv2.putText(img, 'Distacted', (250,400),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                    #mixer.Sound(DistratedAudioFile).play()\n",
    "                    cpt5 +=1\n",
    "                    if cpt5 == 1:\n",
    "                        mixer.Sound(DistratedAudioFile).play()\n",
    "                    if cpt5 >= ALARM_Thresh:\n",
    "                        cpt5 = 0\n",
    "                            \n",
    "            \n",
    "            if DROWSINESS:\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    cpt += 1\n",
    "                    cv2.putText(img, str(cpt), \n",
    "                            (50,100),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            3, (0,0,255),2)\n",
    "                    if cpt >= EYE_AR_CONSEC_FRAMES:\n",
    "                        cv2.putText(img, 'SLEEP ALERT!', (120,100),cv2.FONT_HERSHEY_PLAIN,3, (0,0,255),2)\n",
    "                        cpt = 0 #\n",
    "                        if alarm_status == False:\n",
    "                            alarm_status = True\n",
    "                            if audio_alarm:\n",
    "                                mixer.Sound(ClosedEyesAudioFile).play()\n",
    "                                alarm_status = False #\n",
    "\n",
    "                else:\n",
    "                    cpt = 0\n",
    "                    alarm_status = False\n",
    "\n",
    "                YAWN_THRESH = dist.euclidean(face[78],face[308])/1.5\n",
    "\n",
    "                if dist1 > YAWN_THRESH:\n",
    "                    \n",
    "                    cpt2 += 1\n",
    "                    if cpt2 == 1:\n",
    "                        yawn = True\n",
    "                    \n",
    "                    cv2.putText(img, str(cpt2), (50,150),cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255),2)\n",
    "                    if cpt2 >= YAWN_CONSEC_FRAMES:\n",
    "                        cv2.putText(img, 'Yawn alert', (120,150),cv2.FONT_HERSHEY_PLAIN,3, (0,0,255),2)\n",
    "                        \n",
    "                        if yawn == True:\n",
    "                            yawn = False\n",
    "                            cpt_yawn_per_minute += 1\n",
    "                            if cpt_yawn_per_minute == 1:\n",
    "                                tm = time.time()\n",
    "                        \n",
    "                        if cpt_yawn_per_minute >=  Nb_Yawn:\n",
    "                            print(time.time() - tm)\n",
    "                            if time.time() - tm <= Alarm_time_yawn :\n",
    "                                if alarm_status2 == False:\n",
    "                                    alarm_status2 = True\n",
    "                                    if audio_alarm:\n",
    "                                        mixer.Sound(TiredAudioFile).play()\n",
    "                            else:\n",
    "                                tm = time.time()\n",
    "                                cpt_yawn_per_minute = 1\n",
    "                        \n",
    "                else:\n",
    "                    yawn = False\n",
    "                    cpt2 = 0\n",
    "                    alarm_status2 = False\n",
    "                    \n",
    "                    \n",
    "\n",
    "                cv2.putText(img, 'Yawn: '+str(round(dist1,2)), \n",
    "                            (10,200),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            1.5, (0,255,0),1)\n",
    "                cv2.putText(img, 'EAR: '+str(round(ear,2)), \n",
    "                            (10,240),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            1.5, (0,255,0),1)\n",
    "                \n",
    "                #\n",
    "                cv2.putText(img, 'Yawn per minute : '+str(cpt_yawn_per_minute), \n",
    "                            (10,280),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            1.5, (0,255,0),1)\n",
    "                \n",
    "            \n",
    "            faces.append(face)\n",
    "    \n",
    "#     if Help:\n",
    "#         cv2.putText(img,\"'D': Detect drowsiness \",(20,340),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'S': Detect distraction \",(20,380),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'O': Detect objects \",(20,420),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'H': Show this information \",(20,450),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "    \n",
    "#     if cv2.waitKey(1) ==  ord('h'):\n",
    "#         if Help:\n",
    "#             Help = False\n",
    "#         else:\n",
    "#             Help = True\n",
    "#     if cv2.waitKey(1) ==  ord('d'):\n",
    "#         if DROWSINESS:\n",
    "#             DROWSINESS = False\n",
    "#         else:\n",
    "#             DROWSINESS = True\n",
    "#     if cv2.waitKey(1) ==  ord('s'):\n",
    "#         if DISTRACTION:\n",
    "#             DISTRACTION = False\n",
    "#         else:\n",
    "#             DISTRACTION = True\n",
    "#     if cv2.waitKey(1) ==  ord('o'):\n",
    "#         if OBJ_DETECTION:\n",
    "#             OBJ_DETECTION = False\n",
    "#         else:\n",
    "#             OBJ_DETECTION = True\n",
    "    \n",
    "    #calcul des fps\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    #readapt thresholds according to your fps\n",
    "    EYE_AR_CONSEC_FRAMES = fps * TIME_closed_eyes\n",
    "    YAWN_CONSEC_FRAMES = fps * TIME_open_mouth\n",
    "    ALARM_Thresh = fps * Time_Alarm_Loop\n",
    "    pTime = cTime \n",
    "    cv2.putText(img,f'FPS: {int(fps)}',(20,70),cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0), 3)\n",
    "    cv2.imshow(\"Video\", img)\n",
    "#release the camera and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd43f3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(EYE_AR_CONSEC_FRAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97e6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_yawn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
