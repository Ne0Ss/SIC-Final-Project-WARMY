{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9f1a4e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f7d6e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygame import mixer\n",
    "from scipy.spatial import distance as dist\n",
    "from tensorflow import keras\n",
    "\n",
    "#opencv objects detection\n",
    "classNames=[]\n",
    "with open('ClassNames.txt','r') as f:\n",
    "    for f in classNames:\n",
    "        classNames.append(f)\n",
    "#Audio Files\n",
    "TiredAudioFile = \"AUDIO/GetSomeRest.wav\"\n",
    "DistratedAudioFile = \"AUDIO/StayFocused.wav\"\n",
    "ClosedEyesAudioFile = \"AUDIO/WakeUp.wav\"\n",
    "SmokingAudioFile = \"AUDIO/StopSmoking.wav\"\n",
    "FoodAudioFile = \"AUDIO/StopEating.wav\"\n",
    "PhoneUsageAudioFile = \"AUDIO/PutDownPhone.wav\"\n",
    "#classeIdsof objects to detecte\n",
    "classes= ['1', 30, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 84]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49704b11",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e4868",
   "metadata": {},
   "source": [
    "### FIRST_CONFIGURATION()\n",
    "To adapte our model to the different camera positions, we have to save the default position of the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b927e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FIRST_CONFIGURATION(draw=False, camera=0, info=True):\n",
    "    face_length = 400\n",
    "    pTime = 0\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "\n",
    "    while cv2.waitKey(1) != ord('d') :\n",
    "        success, img= cap.read()\n",
    "        if not success:\n",
    "            print(\"No camera detected\")\n",
    "            break\n",
    "        #converting the image from BGR to RGB\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceMesh.process(imgRGB)\n",
    "        faces = []\n",
    "        if results.multi_face_landmarks:\n",
    "            for faceLms in results.multi_face_landmarks:\n",
    "                if draw:\n",
    "                    mpDraw.draw_landmarks(img,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "                face = []\n",
    "                for id, lm in enumerate(faceLms.landmark):\n",
    "                    ih, iw, ic = img.shape\n",
    "                    x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                    #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                    face.append([x,y])\n",
    "                #calculation distances and facing direction\n",
    "                face_length = dist.euclidean(face[10],face[152])\n",
    "                left_dist_cfg = dist.euclidean(face[1],face[361])\n",
    "                right_dist_cfg = dist.euclidean(face[1],face[132])\n",
    "                direction_cfg= (right_dist_cfg-left_dist_cfg)/face_length\n",
    "                #afficher la direction [-1,1]\n",
    "                if info:\n",
    "                    cv2.putText(img, str(round(direction_cfg,2)), (400,400),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                faces.append(face)\n",
    "        #calculer les fps \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime \n",
    "        cv2.putText(img, \"Take your default driving position and press 'd'\", (20,70),cv2.FONT_HERSHEY_PLAIN,1.5, (255,100,200), 3)\n",
    "        cv2.putText(img,f'FPS: {int(fps)}',(70,400),cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "        cv2.imshow(\"First configuration\", img)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return direction_cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04bfee7",
   "metadata": {},
   "source": [
    "### Time_thresh()\n",
    "To make the alerts smarter and more accurate we used this function to adapte the behavious time threshold to the speed of the vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ac3b240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Time_thresh(speed,MinThresh=2,MaxThresh=10,curve=3):\n",
    "    return(((MaxThresh-MinThresh)/(np.exp(speed/curve)))+MinThresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e3d7d9",
   "metadata": {},
   "source": [
    "Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "de948462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.array(range(101))\n",
    "Speed = 0\n",
    "acceleration = True\n",
    "while cv2.waitKey(10) != 27:\n",
    "    plt.xlabel(\"Speed (km/h)\")\n",
    "    plt.ylabel(\"Time threshold (s)\")\n",
    "    plt.grid('on')\n",
    "    plt.plot(x,Time_thresh(x,curve=5),'r')\n",
    "    plt.plot(Speed, Time_thresh(Speed,curve=5), 'ko')\n",
    "    plt.savefig('ploy.jpg')\n",
    "    img = cv2.imread('ploy.jpg')\n",
    "    cv2.putText(img, str(Speed)+'km/h', (200,60),cv2.FONT_HERSHEY_PLAIN,1.5, (0,0,255), 2)\n",
    "    cv2.putText(img, 'Press ESC to quit', (10,20),cv2.FONT_HERSHEY_PLAIN,1, (0,0,0), 1)\n",
    "    cv2.imshow(\"Time Threshold depending on the speed \",img)\n",
    "    if acceleration:\n",
    "        Speed += 5\n",
    "    else:\n",
    "        Speed -= 5\n",
    "    if Speed==100:\n",
    "        acceleration = False\n",
    "    if Speed==0:\n",
    "        acceleration = True\n",
    "    plt.clf()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12e7d0",
   "metadata": {},
   "source": [
    "### Calculations()\n",
    "Calculates the differente distances of the crucial point to analyse face muscles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "83c21ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculations(face):\n",
    "    left_dist = dist.euclidean(face[1],face[361])\n",
    "    right_dist = dist.euclidean(face[1],face[132])\n",
    "    down_dist = dist.euclidean(face[1],face[0])\n",
    "    \n",
    "    upper_lip=[((face[13][0]+face[312][0]+face[267][0]+face[0][0]+face[37][0]+face[82][0])/6),\n",
    "               ((face[13][1]+face[312][1]+face[267][1]+face[0][1]+face[37][1]+face[82][1])/6)]\n",
    "    lower_lip=[((face[14][0]+face[317][0]+face[314][0]+face[17][0]+face[84][0]+face[87][0])/6),\n",
    "               ((face[14][1]+face[317][1]+face[314][1]+face[17][1]+face[84][1]+face[87][1])/6)]\n",
    "    \n",
    "    A_eye_R = dist.euclidean(face[160],face[144])\n",
    "    B_eye_R = dist.euclidean(face[158],face[153])\n",
    "    C_eye_R = dist.euclidean(face[33],face[133])\n",
    "    R_ear = (A_eye_R + B_eye_R) / (2.0 * C_eye_R)\n",
    "\n",
    "    A_eye_L = dist.euclidean(face[385],face[380])\n",
    "    B_eye_L = dist.euclidean(face[387],face[373])\n",
    "    C_eye_L = dist.euclidean(face[362],face[263])\n",
    "    L_ear = (A_eye_L + B_eye_L) / (2.0 * C_eye_L)\n",
    "    \n",
    "    ear = (R_ear + L_ear) / 2.0\n",
    "    dist1 = dist.euclidean(upper_lip,lower_lip)\n",
    "    \n",
    "    return dist1,left_dist,right_dist,down_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6d1c9",
   "metadata": {},
   "source": [
    "### Model()\n",
    "The main code of ADAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7938fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(draw=True,camera=0, OBJ_DETECTION=True, DISTRACTION=True, DROWSINESS=True, SMOKING=False,\n",
    "          audio_alarm=True, EYE_AR_THRESH=0.2, TIME_closed_eyes=3,TIME_open_mouth=2, Nb_Yawn=3,\n",
    "          Alarm_time_yawn=60, Time_Alarm_Loop=5, direction_cfg = 0):\n",
    "    \n",
    "    #Initialisations\n",
    "    face_length = 400\n",
    "    down_threshold = 30\n",
    "    EYE_AR_CONSEC_FRAMES = 40\n",
    "    YAWN_THRESH = 30\n",
    "    YAWN_CONSEC_FRAMES = 40\n",
    "    ALARM_Thresh = 30\n",
    "    cpt_yawn_per_minute = 0 \n",
    "    alarm_status = False\n",
    "    alarm_status2 = False\n",
    "    cpt = cpt2 = cpt3 = cpt4 = cpt5 = cpt6 = cpt7 = 0\n",
    "    speed = 10\n",
    "\n",
    "    #OBJ DETECTION confguration\n",
    "    configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "    weightsPath = 'frozen_inference_graph.pb'\n",
    "    net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "    net.setInputSize(300,300)\n",
    "    net.setInputScale(1.0/127.5)\n",
    "    net.setInputMean((127.5,127.5,127.5))\n",
    "    net.setInputSwapRB(True)\n",
    "\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "    pTime = 0\n",
    "    while cv2.waitKey(1) != 27 :\n",
    "    #     if cv2.waitKey(1) == ord('a'):\n",
    "    #         speed += 10\n",
    "    #     if cv2.waitKey(1) == ord('d'):\n",
    "    #         speed -= 10\n",
    "    #     if speed> 100:\n",
    "    #         speed = 0\n",
    "    #     if speed<0:\n",
    "    #         speed = 100\n",
    "        #cv2.putText(display,str(round(speed))+'km/h',(200,100),cv2.FONT_HERSHEY_COMPLEX,.8,(0,255,0),2)\n",
    "        success, img= cap.read()\n",
    "        if not success:\n",
    "            print(\"No image!\")\n",
    "            break\n",
    "        display = img\n",
    "        faces = []\n",
    "\n",
    "        ########## OpenCV Object Detection ##########\n",
    "        if OBJ_DETECTION:\n",
    "            classIds, confs, bbox = net.detect(img,confThreshold=0.6)\n",
    "            if len(classIds) != 0:\n",
    "                for classId,confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "                    if classId in classes:\n",
    "                        if draw:\n",
    "                            cv2.rectangle(display,box,color=(0,255,0),thickness=2)\n",
    "                            cv2.putText(display,classNames[classId-1].upper(),(box[0]+10,box[1]+30),cv2.FONT_HERSHEY_COMPLEX,.8,(0,255,0),2)\n",
    "                        if audio_alarm:\n",
    "                            cpt3 += 1\n",
    "                            if cpt3 == 1:\n",
    "                                mixer.Sound(FoodAudioFile).play()\n",
    "                            if cpt3 >= ALARM_Thresh:\n",
    "                                cpt3 = 0\n",
    "                        cv2.putText(display,'FOOD DETECTED',(200,400),cv2.FONT_HERSHEY_COMPLEX,.8,(0,0,255),2)\n",
    "\n",
    "                    if classId==77:\n",
    "                        if draw:\n",
    "                            cv2.rectangle(display,box,color=(0,255,0),thickness=2)\n",
    "                            cv2.putText(display,'CELLPHONE DETECTED',(200,400),cv2.FONT_HERSHEY_COMPLEX,.8,(0,0,255),2)\n",
    "                        if audio_alarm:\n",
    "                            cpt4 += 1\n",
    "                            if cpt4 == 1: \n",
    "                                mixer.Sound(PhoneUsageAudioFile).play()\n",
    "                            if cpt4 >= ALARM_Thresh:\n",
    "                                cpt4 = 0\n",
    "\n",
    "        ########## Smoking Detection ##########\n",
    "        if SMOKING:\n",
    "            predicted=[]\n",
    "            predicted.append(cv2.resize(img, (224,224)))\n",
    "            pred=model.predict(np.array(predicted)/255)\n",
    "            cv2.putText(display,str(round(pred[0][0],2)),(200,200),cv2.FONT_HERSHEY_COMPLEX,.8,(0,0,255),2)\n",
    "            if pred[0][0]>0.02:\n",
    "                cv2.putText(display,'Smoking DETECTED',(200,100),cv2.FONT_HERSHEY_COMPLEX,.8,(0,255,0),2)\n",
    "\n",
    "                if audio_alarm:\n",
    "                    cpt6 +=1\n",
    "                    if cpt6 == 4:\n",
    "                        mixer.Sound(SmokingAudioFile).play()\n",
    "                    if cpt6 >= ALARM_Thresh:\n",
    "                        cpt6 = 0\n",
    "\n",
    "        ########## Mediapipe FaceMesh Detection ##########\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if DISTRACTION or DROWSINESS:\n",
    "            results = faceMesh.process(imgRGB)\n",
    "            if results.multi_face_landmarks:\n",
    "                for faceLms in results.multi_face_landmarks:\n",
    "                    if draw:\n",
    "                        mpDraw.draw_landmarks(display,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "                    face = []\n",
    "                    for id, lm in enumerate(faceLms.landmark):\n",
    "                        ih, iw, ic = img.shape\n",
    "                        x,y,z = int(lm.x*iw), int(lm.y*ih), int(lm.z*ic)\n",
    "                        #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                        face.append([x,y,z])\n",
    "\n",
    "                    down_threshold = down_threshold / face_length\n",
    "                    face_length = dist.euclidean(face[10],face[152])\n",
    "                    down_threshold = down_threshold * face_length\n",
    "                    \n",
    "                    dist1,left_dist,right_dist,down_dist= Calculations(face)\n",
    "                    \n",
    "                    direction= (right_dist-left_dist)/face_length\n",
    "\n",
    "\n",
    "                    ########## Alarm conditions ##########\n",
    "                    if DISTRACTION and speed!=0:\n",
    "                        if direction<-0.5+direction_cfg or down_dist<=down_threshold or direction>0.5+direction_cfg:\n",
    "                            cpt7 += 1\n",
    "                            cv2.putText(display, str(cpt7)+'/'+str(DIST_CONSEC_FRAMES), (150,250),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255),3)\n",
    "                            if cpt7 >= DIST_CONSEC_FRAMES:\n",
    "                                mixer.Sound(DistratedAudioFile).play()\n",
    "                                cpt7 = 0\n",
    "                        else:\n",
    "                            cpt7 = 0\n",
    "\n",
    "                    if DROWSINESS :\n",
    "                        if ear < EYE_AR_THRESH:\n",
    "                            cpt += 1\n",
    "                            cv2.putText(display, str(cpt), \n",
    "                                    (50,100),cv2.FONT_HERSHEY_PLAIN,\n",
    "                                    3, (0,0,255),2)\n",
    "                            if cpt >= EYE_AR_CONSEC_FRAMES:\n",
    "                                cv2.putText(display, 'SLEEP ALERT!', (120,100),cv2.FONT_HERSHEY_PLAIN,3, (0,0,255),2)\n",
    "                                cpt = 0 #\n",
    "                                if alarm_status == False:\n",
    "                                    alarm_status = True\n",
    "                                    if audio_alarm:\n",
    "                                        mixer.Sound(ClosedEyesAudioFile).play()\n",
    "                                        alarm_status = False #\n",
    "\n",
    "                        else:\n",
    "                            cpt = 0\n",
    "                            alarm_status = False\n",
    "\n",
    "                        YAWN_THRESH = dist.euclidean(face[78],face[308])/1.5\n",
    "\n",
    "                        if dist1 > YAWN_THRESH:\n",
    "                            cpt2 += 1\n",
    "                            if cpt2 == 1:\n",
    "                                yawn = True\n",
    "                            cv2.putText(display, str(cpt2), (50,150),cv2.FONT_HERSHEY_PLAIN, 3, (0,0,255),2)\n",
    "                            if cpt2 >= YAWN_CONSEC_FRAMES:\n",
    "                                cv2.putText(img, 'Yawn alert', (120,150),cv2.FONT_HERSHEY_PLAIN,3, (0,0,255),2)\n",
    "                                if yawn == True:\n",
    "                                    yawn = False\n",
    "                                    cpt_yawn_per_minute += 1\n",
    "                                    if cpt_yawn_per_minute == 1:\n",
    "                                        tm = time.time()\n",
    "                                if cpt_yawn_per_minute >=  Nb_Yawn:\n",
    "                                    if time.time() - tm <= Alarm_time_yawn :\n",
    "                                        if alarm_status2 == False:\n",
    "                                            alarm_status2 = True\n",
    "                                            if audio_alarm:\n",
    "                                                mixer.Sound(TiredAudioFile).play()\n",
    "                                    else:\n",
    "                                        tm = time.time()\n",
    "                                        cpt_yawn_per_minute = 1\n",
    "                        else:\n",
    "                            yawn = False\n",
    "                            cpt2 = 0\n",
    "                            alarm_status2 = False\n",
    "\n",
    "\n",
    "\n",
    "                        cv2.putText(display, 'Yawn: '+str(round(dist1,2)), \n",
    "                                    (10,200),cv2.FONT_HERSHEY_PLAIN,\n",
    "                                    1.5, (0,255,0),1)\n",
    "                        cv2.putText(display, 'EAR: '+str(round(ear,2)), \n",
    "                                    (10,240),cv2.FONT_HERSHEY_PLAIN,\n",
    "                                    1.5, (0,255,0),1)\n",
    "\n",
    "                        #\n",
    "                        cv2.putText(display, 'Yawn per minute : '+str(cpt_yawn_per_minute), \n",
    "                                    (10,280),cv2.FONT_HERSHEY_PLAIN,\n",
    "                                    1.5, (0,255,0),1)\n",
    "                        \n",
    "                    faces.append(face)\n",
    "\n",
    "    #     if Help:\n",
    "    #         cv2.putText(img,\"'D': Detect drowsiness \",(20,340),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "    #         cv2.putText(img,\"'S': Detect distraction \",(20,380),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "    #         cv2.putText(img,\"'O': Detect objects \",(20,420),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "    #         cv2.putText(img,\"'H': Show this information \",(20,450),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "\n",
    "    #     if cv2.waitKey(1) ==  ord('h'):\n",
    "    #         if Help:\n",
    "    #             Help = False\n",
    "    #         else:\n",
    "    #             Help = True\n",
    "    #     if cv2.waitKey(1) ==  ord('d'):\n",
    "    #         if DROWSINESS:\n",
    "    #             DROWSINESS = False\n",
    "    #         else:\n",
    "    #             DROWSINESS = True\n",
    "    #     if cv2.waitKey(1) ==  ord('s'):\n",
    "    #         if DISTRACTION:\n",
    "    #             DISTRACTION = False\n",
    "    #         else:\n",
    "    #             DISTRACTION = True\n",
    "    #     if cv2.waitKey(1) ==  ord('o'):\n",
    "    #         if OBJ_DETECTION:\n",
    "    #             OBJ_DETECTION = False\n",
    "    #         else:\n",
    "    #             OBJ_DETECTION = True\n",
    "\n",
    "        #calcul des fps\n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        #readapt thresholds according to your fps\n",
    "        DIST_CONSEC_FRAMES = fps * Time_thresh(speed,2,15,5)\n",
    "        EYE_AR_CONSEC_FRAMES = fps * TIME_closed_eyes\n",
    "        YAWN_CONSEC_FRAMES = fps * TIME_open_mouth\n",
    "        ALARM_Thresh = fps * Time_Alarm_Loop\n",
    "        pTime = cTime \n",
    "        cv2.putText(img,f'FPS: {int(fps)}',(20,70),cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0), 3)\n",
    "        cv2.imshow(\"ADAS\", display)\n",
    "\n",
    "    #     if cv2.waitKey(1) == ord('a'):\n",
    "    #         cv2.imwrite(\"image4.png\",display)\n",
    "\n",
    "    #     plt.xlabel(\"Speed (km/h)\")\n",
    "    #     plt.ylabel(\"Time threshold (s)\")\n",
    "    #     plt.grid('on')\n",
    "    #     x=np.array(range(50))\n",
    "    #     plt.plot(x,Time_thresh(x),'r')\n",
    "    #     plt.plot(speed, Time_thresh(speed), 'bo')\n",
    "    #     plt.savefig('ploy.jpg')\n",
    "    #     cv2.imshow(\"plot\",cv2.imread('ploy.jpg'))\n",
    "    #     plt.clf()\n",
    "\n",
    "    #release the camera and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ae7d5e",
   "metadata": {},
   "source": [
    "# Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fd176048",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = False\n",
    "First_cfg = False\n",
    "\n",
    "OBJ_DETECTION = False\n",
    "DISTRACTION = True\n",
    "DROWSINESS = False\n",
    "SMOKING = False\n",
    "\n",
    "audio_alarm = True\n",
    "EYE_AR_THRESH = 0.2\n",
    "TIME_closed_eyes = 3 #seconds\n",
    "TIME_open_mouth = 2 #seconds\n",
    "Nb_Yawn = 3 # Number of Yawnings per 'Alarm_time_yawn'\n",
    "Alarm_time_yawn = 60 #Seconds \n",
    "Time_Alarm_Loop = 5   #Seconds \n",
    "camera = 0 #Camera id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b1897",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "abf9b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "model = keras.models.load_model('smoking_model')\n",
    "#face mesh params and drawing options\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n",
    "drawSpec = mpDraw.DrawingSpec(thickness=1,circle_radius=0)\n",
    "\n",
    "if First_cfg:\n",
    "    direction_cfg = FIRST_CONFIGURATION()\n",
    "Model(draw,camera, OBJ_DETECTION, DISTRACTION, DROWSINESS,SMOKING,audio_alarm, EYE_AR_THRESH,\n",
    "      TIME_closed_eyes,TIME_open_mouth, Nb_Yawn,Alarm_time_yawn, Time_Alarm_Loop, direction_cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
