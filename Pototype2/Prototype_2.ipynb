{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a66d27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "from pygame import mixer\n",
    "from scipy.spatial import distance as dist\n",
    "mixer.init()\n",
    "#face mesh params and drawing otions\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpFaceMesh = mp.solutions.face_mesh\n",
    "faceMesh = mpFaceMesh.FaceMesh(max_num_faces=1)\n",
    "drawSpec = mpDraw.DrawingSpec(thickness=1,circle_radius=0)\n",
    "camera = 0\n",
    "\n",
    "#opencv objects detection\n",
    "classNames = ['person', '0', '0', '0', '0', '0', '0', '0','0', '0', '0', '0', '0', '0',\n",
    "              '0', '0', '0', '0', '0', '0', '0', '0', '0', '0','0', '0', '0', '0', '0',\n",
    "              'eye glasses', '0', '0','0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
    "              '0', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "              'banana', 'apple', 'sandwich','orange', 'broccoli', 'carrot', 'hot dog', \n",
    "              'pizza', 'donut', 'cake', '0', '0','0', '0', '0', '0', '0', '0', '0','0',\n",
    "              '0', '0', '0', '0', '0', 'cell phone', '0', '0','0', '0', '0', '0', 'book',\n",
    "              '0', '0', '0','0', '0', '0', '0']\n",
    "\n",
    "# options = \"options.txt\"\n",
    "# with open(options,'r') as f:\n",
    "#     print(f)\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "if setup:\n",
    "    ### PARAMETRES ###\n",
    "    draw = True\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    face_length = 400\n",
    "    down_threshold = 30\n",
    "    EYE_AR_CONSEC_FRAMES = 40\n",
    "    YAWN_THRESH = 30\n",
    "    YAWN_CONSEC_FRAMES = 40\n",
    "    alarm_status = False\n",
    "    alarm_status2 = False\n",
    "    pTime = 0\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "\n",
    "    while cv2.waitKey(1) != ord('d') :\n",
    "        success, img= cap.read()\n",
    "        if not success:\n",
    "            print(\"No camera detected\")\n",
    "            break\n",
    "        #converting the image from BGR to RGB\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = faceMesh.process(imgRGB)\n",
    "        faces = []\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for faceLms in results.multi_face_landmarks:\n",
    "                if draw:\n",
    "                    mpDraw.draw_landmarks(img,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "                face = []\n",
    "                for id, lm in enumerate(faceLms.landmark):\n",
    "                    ih, iw, ic = img.shape\n",
    "                    x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                    #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                    face.append([x,y])\n",
    "                #calculation distances and facing direction\n",
    "                down_threshold = down_threshold / face_length\n",
    "                face_length = dist.euclidean(face[10],face[152])\n",
    "                down_threshold = down_threshold * face_length\n",
    "                left_dist_cfg = dist.euclidean(face[1],face[361])\n",
    "                right_dist_cfg = dist.euclidean(face[1],face[132])\n",
    "                down_dist= dist.euclidean(face[1],face[0])\n",
    "                direction_cfg= (right_dist_cfg-left_dist_cfg)/face_length\n",
    "                #afficher la direction [-1,1]\n",
    "                cv2.putText(img, str(round(direction_cfg,2)), (400,400),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "\n",
    "                faces.append(face)\n",
    "        #calculer les fps \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime \n",
    "        cv2.putText(img, \"Prenez votre position de conduite par defaut\", (20,70),cv2.FONT_HERSHEY_PLAIN,1.5, (255,100,200), 3)\n",
    "        cv2.putText(img,f'FPS: {int(fps)}',(70,400),cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0), 2)\n",
    "        cv2.imshow(\"Video\", img)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "##########################################################################################################################\n",
    "\n",
    "### PARAMETRES ###\n",
    "\n",
    "OBJ_DETECTION = False\n",
    "DISTRACTION = True\n",
    "DROWSINESS = True\n",
    "\n",
    "draw = True\n",
    "audio_alarm = True\n",
    "EYE_AR_THRESH = 0.2\n",
    "TIME_closed_eyes = 2\n",
    "TIME_open_mouth = 2\n",
    "\n",
    "Help = False\n",
    "TiredAudioFile = \"AUDIO/malek.wav\"\n",
    "DistratedAudioFile = \"AUDIO/malek.wav\"\n",
    "\n",
    "#classeIdsof objects to detecte\n",
    "classes= ['1', 30, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 77, 84] \n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "face_length = 400\n",
    "down_threshold = 30\n",
    "EYE_AR_CONSEC_FRAMES = 40\n",
    "YAWN_THRESH = 30\n",
    "YAWN_CONSEC_FRAMES = 40\n",
    "cpt = 0\n",
    "cpt2 = 0\n",
    "alarm_status = False\n",
    "alarm_status2 = False\n",
    "configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "weightsPath = 'frozen_inference_graph.pb'\n",
    "net = cv2.dnn_DetectionModel(weightsPath,configPath)\n",
    "net.setInputSize(320,320)\n",
    "net.setInputScale(1.0/127.5)\n",
    "net.setInputMean((127.5,127.5,127.5))\n",
    "net.setInputSwapRB(True)\n",
    "\n",
    "cap = cv2.VideoCapture(camera)\n",
    "pTime = 0\n",
    "while cv2.waitKey(1) != 27 :\n",
    "    success, img= cap.read()\n",
    "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    results = faceMesh.process(imgRGB)\n",
    "    faces = []\n",
    "    ########## OpenCV Object Detection ##########\n",
    "    if OBJ_DETECTION:\n",
    "        classIds, confs, bbox = net.detect(img,confThreshold=0.6)\n",
    "        if len(classIds) != 0:\n",
    "            for classId,confidence,box in zip(classIds.flatten(),confs.flatten(),bbox):\n",
    "                if classId in classes:\n",
    "                    cv2.rectangle(img,box,color=(0,255,0),thickness=2)\n",
    "                    cv2.putText(img,classNames[classId-1].upper(),(box[0]+10,box[1]+30),cv2.FONT_HERSHEY_COMPLEX,.8,(0,255,0),2)\n",
    "                if classId==77:\n",
    "                    cv2.putText(img,'CELLPHONE DETECTED',(200,400),cv2.FONT_HERSHEY_COMPLEX,.8,(0,0,255),2)\n",
    "    ########## Mediapipe FaceMesh Detection ##########\n",
    "    if results.multi_face_landmarks:\n",
    "        for faceLms in results.multi_face_landmarks:\n",
    "            if draw:\n",
    "                mpDraw.draw_landmarks(img,faceLms,mpFaceMesh.FACEMESH_CONTOURS,drawSpec,drawSpec)\n",
    "            face = []\n",
    "            for id, lm in enumerate(faceLms.landmark):\n",
    "                ih, iw, ic = img.shape\n",
    "                x,y = int(lm.x*iw), int(lm.y*ih)\n",
    "                #cv2.putText(img, str(id), (x,y),cv2.FONT_HERSHEY_PLAIN,0.8, (0,255,0), 1)\n",
    "                face.append([x,y])\n",
    "            down_threshold = down_threshold / face_length\n",
    "            face_length = dist.euclidean(face[10],face[152])\n",
    "            down_threshold = down_threshold * face_length\n",
    "            left_dist = dist.euclidean(face[1],face[361])\n",
    "            right_dist= dist.euclidean(face[1],face[132])\n",
    "            down_dist= dist.euclidean(face[1],face[0])\n",
    "            direction= (right_dist-left_dist)/face_length\n",
    "            \n",
    "            upper_lip=[((face[13][0]+face[312][0]+face[267][0]+face[0][0]+face[37][0]+face[82][0])/6),\n",
    "                        ((face[13][1]+face[312][1]+face[267][1]+face[0][1]+face[37][1]+face[82][1])/6)]\n",
    "\n",
    "            lower_lip=[((face[14][0]+face[317][0]+face[314][0]+face[17][0]+face[84][0]+face[87][0])/6),\n",
    "                        ((face[14][1]+face[317][1]+face[314][1]+face[17][1]+face[84][1]+face[87][1])/6)]\n",
    "\n",
    "            A_eye_R = dist.euclidean(face[160],face[144])\n",
    "            B_eye_R = dist.euclidean(face[158],face[153])\n",
    "            C_eye_R = dist.euclidean(face[33],face[133])\n",
    "            R_ear = (A_eye_R + B_eye_R) / (2.0 * C_eye_R)\n",
    "\n",
    "            A_eye_L = dist.euclidean(face[385],face[380])\n",
    "            B_eye_L = dist.euclidean(face[387],face[373])\n",
    "            C_eye_L = dist.euclidean(face[362],face[263])\n",
    "            L_ear = (A_eye_L + B_eye_L) / (2.0 * C_eye_L)\n",
    "\n",
    "            ear = (R_ear + L_ear) / 2.0\n",
    "            dist1 = dist.euclidean(upper_lip,lower_lip)\n",
    "            \n",
    "            ########## Alarm conditions ##########\n",
    "            if DISTRACTION:\n",
    "                if direction>=-0.5+direction_cfg and direction<=0.5+direction_cfg and down_dist>down_threshold:\n",
    "                    cv2.putText(img, 'Good', (150,400),cv2.FONT_HERSHEY_PLAIN,2, (0,255,0), 3)\n",
    "                if direction>0.5+direction_cfg:\n",
    "                    cv2.putText(img, 'Distacted', (350,250),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                if direction<-0.5+direction_cfg:\n",
    "                    cv2.putText(img, 'Distacted', (150,250),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "                if down_dist<=down_threshold:\n",
    "                    cv2.putText(img, 'Distacted', (250,400),cv2.FONT_HERSHEY_PLAIN,2, (0,0,255), 3)\n",
    "            \n",
    "            if DROWSINESS:\n",
    "                if ear < EYE_AR_THRESH:\n",
    "                    cpt += 1\n",
    "                    cv2.putText(img, str(cpt), \n",
    "                            (50,100),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            3, (0,0,255),2)\n",
    "                    if cpt >= EYE_AR_CONSEC_FRAMES:\n",
    "\n",
    "                        cv2.putText(img, 'SLEEP ALERT!', \n",
    "                            (120,100),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            3, (0,0,255),2)\n",
    "\n",
    "                        if alarm_status == False:\n",
    "                            alarm_status = True\n",
    "                            if audio_alarm:\n",
    "                                mixer.Sound(TiredAudioFile).play()\n",
    "\n",
    "                else:\n",
    "                    cpt = 0\n",
    "                    alarm_status = False\n",
    "\n",
    "                YAWN_THRESH = dist.euclidean(face[78],face[308])/1.5 \n",
    "                if dist1 > YAWN_THRESH:\n",
    "                    cpt2 += 1\n",
    "                    cv2.putText(img, str(cpt2), \n",
    "                            (50,150),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            3, (0,0,255),2)\n",
    "                    if cpt2 >= YAWN_CONSEC_FRAMES:\n",
    "                        cv2.putText(img, 'Yawn alert', \n",
    "                                (120,150),cv2.FONT_HERSHEY_PLAIN,\n",
    "                                3, (0,0,255),2)\n",
    "                        if alarm_status2 == False:\n",
    "                            alarm_status2 = True\n",
    "                            if audio_alarm:\n",
    "                                mixer.Sound(TiredAudioFile).play()\n",
    "                else:\n",
    "                    cpt2 = 0\n",
    "                    alarm_status2 = False\n",
    "\n",
    "                cv2.putText(img, 'Yawn: '+str(round(dist1,2)), \n",
    "                            (10,200),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            1.5, (0,255,0),1)\n",
    "                cv2.putText(img, 'EAR: '+str(round(ear,2)), \n",
    "                            (10,240),cv2.FONT_HERSHEY_PLAIN,\n",
    "                            1.5, (0,255,0),1)\n",
    "            \n",
    "            faces.append(face)\n",
    "    \n",
    "#     if Help:\n",
    "#         cv2.putText(img,\"'D': Detect drowsiness \",(20,340),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'S': Detect distraction \",(20,380),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'O': Detect objects \",(20,420),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "#         cv2.putText(img,\"'H': Show this information \",(20,450),cv2.FONT_HERSHEY_PLAIN, 1, (10,50,10), 2)\n",
    "    \n",
    "#     if cv2.waitKey(1) ==  ord('h'):\n",
    "#         if Help:\n",
    "#             Help = False\n",
    "#         else:\n",
    "#             Help = True\n",
    "#     if cv2.waitKey(1) ==  ord('d'):\n",
    "#         if DROWSINESS:\n",
    "#             DROWSINESS = False\n",
    "#         else:\n",
    "#             DROWSINESS = True\n",
    "#     if cv2.waitKey(1) ==  ord('s'):\n",
    "#         if DISTRACTION:\n",
    "#             DISTRACTION = False\n",
    "#         else:\n",
    "#             DISTRACTION = True\n",
    "#     if cv2.waitKey(1) ==  ord('o'):\n",
    "#         if OBJ_DETECTION:\n",
    "#             OBJ_DETECTION = False\n",
    "#         else:\n",
    "#             OBJ_DETECTION = True\n",
    "    \n",
    "    #calcul des fps\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime-pTime)\n",
    "    #readapt thresholds according to your fps\n",
    "    EYE_AR_CONSEC_FRAMES = fps * TIME_closed_eyes\n",
    "    YAWN_CONSEC_FRAMES = fps * TIME_open_mouth\n",
    "    pTime = cTime \n",
    "    cv2.putText(img,f'FPS: {int(fps)}',(20,70),cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0), 3)\n",
    "    cv2.imshow(\"Video\", img)\n",
    "#release the camera and close the windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ed353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
